import re
import unicodedata

# ==========================================
# 1ï¸âƒ£ LOAD RAW TEXT
# ==========================================
with open("law_raw.txt", "r", encoding="utf-8") as f:
    text = f.read()

text = unicodedata.normalize("NFKC", text)

# ==========================================
# 2ï¸âƒ£ CLEANING PATTERNS
# ==========================================

# --- A) Remove the almeezan URL + page number (e.g., "https://...ar 1/7") ---
text = re.sub(r'https?://www\.almeezan\.qa/\S+\s*\d+/\d+', '', text)

# --- B) Remove the repeated law title + date on each page ---
text = re.sub(
    r'.*(?:ï»—ïºï»§ï»®ï»§|Ù‚Ø§Ù†ÙˆÙ†)\s*(?:ïº­ï»—ï»¡|Ø±Ù‚Ù…)\s*\(13\)\s*(?:ï»Ÿïº³ï»§ïº”|Ù„Ø³Ù†Ø©)\s*2024\s*(?:ïº‘ïº·ïº„ï»¥|Ø¨Ø´Ø£Ù†).*?(?:10[:/]02[:/]2026|10:41).*',
    '',
    text
)
text = re.sub(
    r'.*(?:ï»—ïºï»§ï»®ï»§|Ù‚Ø§Ù†ÙˆÙ†)\s*(?:ïº­ï»—ï»¡|Ø±Ù‚Ù…)\s*\(13\)\s*(?:ï»Ÿïº³ï»§ïº”|Ù„Ø³Ù†Ø©)\s*2024\s*(?:ïº‘ïº·ïº„ï»¥|Ø¨Ø´Ø£Ù†).*(?:ïºï»Ÿï»Œïºï»£ïº”|Ø§Ù„Ø¹Ø§Ù…Ø©).*\n?',
    '',
    text
)

# --- C) Remove the date/time pattern standalone ---
text = re.sub(r'\d{2}/\d{2}/\d{4}\s*\d{1,2}:\d{2}', '', text)

# --- D) Remove footer (Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¹Ø¯Ù… Ø§Ø¹ØªØ¨Ø§Ø±... + copyright) ---
text = re.sub(r'.*Ø§Ù„Ø±Ø¬Ø§Ø¡\s+Ø¹Ø¯Ù…\s+Ø§Ø¹ØªØ¨Ø§Ø±.*', '', text)
text = re.sub(r'.*ïºï»Ÿïº­ïºŸïºïº€\s+.*(?:ïº­ïº³ï»£ï¯¾ïº”|Ø±Ø³Ù…ÙŠØ©).*', '', text)
text = re.sub(r'Â©.*$', '', text, flags=re.MULTILINE)

# --- E) Clean up extra whitespace ---
text = re.sub(r'\r\n', '\n', text)
text = re.sub(r'[ \t]+', ' ', text)
text = re.sub(r'\n{3,}', '\n\n', text)
text = text.strip()

# ==========================================
# 3ï¸âƒ£ SAVE CLEANED TEXT
# ==========================================
with open("law_structured.txt", "w", encoding="utf-8") as f:
    f.write(text)

print("âœ… Cleaned text saved to law_structured.txt")
print(f"ğŸ“ Length: {len(text)} characters")

print("\n--- First 500 chars ---")
print(text[:500])
print("\n--- Last 300 chars ---")
print(text[-300:])